{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-10T11:55:42.117111Z",
     "start_time": "2026-02-10T11:55:42.109604Z"
    }
   },
   "source": "import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport matplotlib.font_manager as fm\n\n# Register Sarabun font for Thai text rendering\n_sarabun_path = \"/System/Library/AssetsV2/com_apple_MobileAsset_Font7/bff515501313f56409358f8994642696000d2dbc.asset/AssetData/Sarabun.ttc\"\nfm.fontManager.addfont(_sarabun_path)\n_sarabun_name = fm.FontProperties(fname=_sarabun_path).get_name()\n\nplt.rcParams[\"font.family\"] = _sarabun_name\nplt.rcParams[\"axes.unicode_minus\"] = False\nplt.rcParams[\"figure.figsize\"] = (14, 6)\nplt.rcParams[\"axes.grid\"] = True\nplt.rcParams[\"grid.alpha\"] = 0.3\n\nDATA_DIR = Path(\"../data/smiley159\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T11:55:42.459645Z",
     "start_time": "2026-02-10T11:55:42.397987Z"
    }
   },
   "cell_type": "code",
   "source": "# ── Load reference data ──────────────────────────────────────────────\ncommon = json.loads((DATA_DIR / \"common-data.json\").read_text(\"utf-8\"))\nparties_raw = json.loads((DATA_DIR / \"party-data.json\").read_text(\"utf-8\"))[\"parties\"]\ncandidates_raw = json.loads((DATA_DIR / \"candidate-data.json\").read_text(\"utf-8\"))[\"candidates\"]\nsummary_raw = json.loads((DATA_DIR / \"summary.json\").read_text(\"utf-8\"))\n\n# Area / province / region lookup tables\narea_df = pd.DataFrame(common[\"areas\"])[[\"code\", \"provinceCode\", \"number\", \"name\", \"win66PartyCode\"]].rename(\n    columns={\"code\": \"areaCode\", \"number\": \"areaNo\", \"name\": \"areaName\"}\n)\nprovince_df = pd.DataFrame(common[\"provinces\"])[[\"code\", \"regionCode\", \"name\"]].rename(\n    columns={\"code\": \"provinceCode\", \"name\": \"provinceName\"}\n)\nregion_df = pd.DataFrame(common[\"regions\"])[[\"code\", \"name\"]].rename(\n    columns={\"code\": \"regionCode\", \"name\": \"regionName\"}\n)\narea_meta = (\n    area_df\n    .merge(province_df, on=\"provinceCode\", how=\"left\")\n    .merge(region_df, on=\"regionCode\", how=\"left\")\n)\n\n# Party lookup\nparty_df = pd.DataFrame(parties_raw)[[\"code\", \"number\", \"name\", \"colorPrimary\"]].rename(\n    columns={\"code\": \"partyCode\", \"number\": \"partyNo\", \"name\": \"partyName\", \"colorPrimary\": \"partyColor\"}\n)\n\nprint(f\"Areas: {len(area_meta)}, Provinces: {province_df.shape[0]}, Regions: {region_df.shape[0]}, Parties: {len(party_df)}\")\narea_meta.head()",
   "id": "2ecf651d251efd2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T11:55:42.692681Z",
     "start_time": "2026-02-10T11:55:42.685752Z"
    }
   },
   "cell_type": "code",
   "source": "# ── Flatten constituency results into one row per (area, candidate) ──\nconst_raw = json.loads((DATA_DIR / \"all-areas-constituency-results.json\").read_text(\"utf-8\"))\n\nrows = []\nfor area in const_raw[\"areas\"]:\n    base = {\n        \"areaCode\": area[\"areaCode\"],\n        \"goodVotes\": area[\"goodVotes\"],\n        \"badVotes\": area[\"badVotes\"],\n        \"noVotes\": area[\"noVotes\"],\n        \"totalVotes\": area[\"totalVotes\"],\n        \"totalEligibleVoters\": area.get(\"totalEligibleVoters\", 0),\n        \"voteProgressPercent\": area.get(\"voteProgressPercent\", 0),\n    }\n    for e in area[\"entries\"]:\n        rows.append({**base, **e})\n\nconst_df = (\n    pd.DataFrame(rows)\n    .merge(party_df, on=\"partyCode\", how=\"left\")\n    .merge(area_meta, on=\"areaCode\", how=\"left\")\n)\n\n# ── Flatten party-list results into one row per (area, party) ────────\npl_raw = json.loads((DATA_DIR / \"all-areas-party-list-results.json\").read_text(\"utf-8\"))\n\nrows = []\nfor area in pl_raw[\"areas\"]:\n    base = {\n        \"areaCode\": area[\"areaCode\"],\n        \"goodVotes_pl\": area[\"goodVotes\"],\n        \"badVotes_pl\": area[\"badVotes\"],\n        \"noVotes_pl\": area[\"noVotes\"],\n        \"totalVotes_pl\": area[\"totalVotes\"],\n        \"voteProgressPercent_pl\": area.get(\"voteProgressPercent\", 0),\n    }\n    for e in area[\"entries\"]:\n        rows.append({**base, **e})\n\npl_df = (\n    pd.DataFrame(rows)\n    .rename(columns={\"voteTotal\": \"voteTotal_pl\", \"votePercent\": \"votePercent_pl\", \"rank\": \"rank_pl\"})\n    .merge(party_df, on=\"partyCode\", how=\"left\")\n    .merge(area_meta, on=\"areaCode\", how=\"left\")\n)\n\nprint(f\"Constituency rows: {len(const_df):,}  |  Party-list rows: {len(pl_df):,}\")\nconst_df.head()",
   "id": "9d4f3f08b06da3bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T11:55:43.939457Z",
     "start_time": "2026-02-10T11:55:43.885977Z"
    }
   },
   "cell_type": "code",
   "source": "# ── Area-level summary (one row per area) ────────────────────────────\narea_summary = (\n    const_df\n    .drop_duplicates(\"areaCode\")\n    [[\"areaCode\", \"areaName\", \"areaNo\", \"provinceName\", \"regionName\",\n      \"goodVotes\", \"badVotes\", \"noVotes\", \"totalVotes\", \"totalEligibleVoters\",\n      \"voteProgressPercent\"]]\n    .copy()\n)\narea_summary[\"turnout\"] = area_summary[\"totalVotes\"] / area_summary[\"totalEligibleVoters\"]\narea_summary[\"badVoteRate\"] = area_summary[\"badVotes\"] / area_summary[\"totalVotes\"]\narea_summary[\"noVoteRate\"] = area_summary[\"noVotes\"] / area_summary[\"totalVotes\"]\n\n# Winner per area (rank == 1)\nwinners = const_df[const_df[\"rank\"] == 1][[\"areaCode\", \"partyCode\", \"partyName\", \"partyColor\", \"voteTotal\", \"votePercent\"]].rename(\n    columns={\"voteTotal\": \"winnerVotes\", \"votePercent\": \"winnerPct\", \"partyName\": \"winnerParty\", \"partyColor\": \"winnerColor\"}\n)\narea_summary = area_summary.merge(winners, on=\"areaCode\", how=\"left\")\n\n# Runner-up\nrunners = const_df[const_df[\"rank\"] == 2][[\"areaCode\", \"voteTotal\", \"partyName\"]].rename(\n    columns={\"voteTotal\": \"runnerUpVotes\", \"partyName\": \"runnerUpParty\"}\n)\narea_summary = area_summary.merge(runners, on=\"areaCode\", how=\"left\")\narea_summary[\"winMargin\"] = (area_summary[\"winnerVotes\"] - area_summary[\"runnerUpVotes\"]) / area_summary[\"goodVotes\"]\n\nprint(f\"Area summary: {len(area_summary)} areas\")\narea_summary.describe()",
   "id": "60177ae3fafab8a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "outputs": [],
   "execution_count": null,
   "source": "## Hypothesis: Vote-buying \"number spillover\"\n\nVoters get 2 papers — **constituency** (candidate number only) and **party list** (party number + name). Candidate numbers are random per area, but party-list numbers are fixed nationally.\n\n**If vote-buying happens**, voters are told \"vote number X\" for the constituency candidate. Confused voters write the same number X on the party-list paper too — accidentally boosting whichever small party happens to have national number X.\n\n**Test**: For each area's winning constituency candidate (number N), check if party-list party #N got **excess votes** compared to its national average.",
   "id": "16842de24e0c4c46"
  },
  {
   "cell_type": "code",
   "id": "27nz3z5insn",
   "source": "# ── Build candidate number lookup ────────────────────────────────────\ncand_df = pd.DataFrame(candidates_raw)[[\"code\", \"areaCode\", \"partyCode\", \"number\"]].rename(\n    columns={\"code\": \"candidateCode\", \"number\": \"candidateNo\"}\n)\n\n# ── Add candidateNo to constituency results ─────────────────────────\nconst_with_no = const_df.merge(\n    cand_df[[\"candidateCode\", \"candidateNo\"]],\n    on=\"candidateCode\",\n    how=\"left\",\n)\n\n# ── Party-list: party number → partyCode mapping ────────────────────\npartyno_to_code = party_df.set_index(\"partyNo\")[\"partyCode\"].to_dict()\npartyno_to_name = party_df.set_index(\"partyNo\")[\"partyName\"].to_dict()\n\n# ── Party-list national average vote share per party ─────────────────\npl_national = (\n    pl_df\n    .groupby(\"partyCode\")\n    .agg(totalVotes_pl=(\"voteTotal_pl\", \"sum\"), nAreas=(\"areaCode\", \"nunique\"))\n    .reset_index()\n)\ntotal_pl_votes = pl_df.drop_duplicates(\"areaCode\")[\"goodVotes_pl\"].sum()\npl_national[\"nationalPct\"] = pl_national[\"totalVotes_pl\"] / total_pl_votes * 100\n\nprint(f\"Total party-list good votes nationally: {total_pl_votes:,.0f}\")\npl_national.sort_values(\"nationalPct\", ascending=False).head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "t96m77m39bs",
   "source": "# ── Core analysis: For each area's top candidates, find same-numbered party-list party ──\n# Focus on top-3 candidates per area (most likely to be vote-bought)\ntop_cands = const_with_no[const_with_no[\"rank\"] <= 3].copy()\n\n# Map candidateNo → the party-list party with that same number\ntop_cands[\"pl_partyCode_sameNo\"] = top_cands[\"candidateNo\"].map(partyno_to_code)\ntop_cands[\"pl_partyName_sameNo\"] = top_cands[\"candidateNo\"].map(partyno_to_name)\n\n# Get the actual party-list vote for that same-numbered party in this area\npl_lookup = pl_df[[\"areaCode\", \"partyCode\", \"voteTotal_pl\", \"votePercent_pl\", \"goodVotes_pl\"]].rename(\n    columns={\"partyCode\": \"pl_partyCode_sameNo\",\n             \"voteTotal_pl\": \"pl_sameNo_votes\",\n             \"votePercent_pl\": \"pl_sameNo_pct\"}\n)\n\ntop_cands = top_cands.merge(pl_lookup, on=[\"areaCode\", \"pl_partyCode_sameNo\"], how=\"left\")\n\n# Add the national average for this same-numbered party\npl_nat_lookup = pl_national[[\"partyCode\", \"nationalPct\"]].rename(\n    columns={\"partyCode\": \"pl_partyCode_sameNo\", \"nationalPct\": \"pl_sameNo_nationalPct\"}\n)\ntop_cands = top_cands.merge(pl_nat_lookup, on=\"pl_partyCode_sameNo\", how=\"left\")\n\n# Compute excess: how much more this party-list party got in this area vs national avg\ntop_cands[\"pl_excess_pct\"] = top_cands[\"pl_sameNo_pct\"] - top_cands[\"pl_sameNo_nationalPct\"]\ntop_cands[\"pl_excess_votes\"] = top_cands[\"pl_sameNo_votes\"] - (top_cands[\"pl_sameNo_nationalPct\"] / 100 * top_cands[\"goodVotes_pl\"])\n\n# Flag: is the same-numbered party a \"small\" party? (national share < 2%)\ntop_cands[\"pl_sameNo_isSmall\"] = top_cands[\"pl_sameNo_nationalPct\"] < 2\n\nprint(f\"Rows with valid same-number mapping: {top_cands['pl_sameNo_votes'].notna().sum()}\")\nprint(f\"Of which map to a small party: {(top_cands['pl_sameNo_isSmall'] & top_cands['pl_sameNo_votes'].notna()).sum()}\")\n\n# Show most suspicious cases: winner's number maps to small party, big excess\nsuspicious = (\n    top_cands[\n        (top_cands[\"rank\"] == 1) &\n        (top_cands[\"pl_sameNo_isSmall\"]) &\n        (top_cands[\"pl_excess_pct\"] > 0)\n    ]\n    .sort_values(\"pl_excess_pct\", ascending=False)\n    [[\"areaCode\", \"areaName\", \"provinceName\", \"regionName\",\n      \"partyName\", \"candidateNo\", \"voteTotal\", \"votePercent\",\n      \"pl_partyName_sameNo\", \"pl_sameNo_pct\", \"pl_sameNo_nationalPct\",\n      \"pl_excess_pct\", \"pl_excess_votes\"]]\n)\nprint(f\"\\nSuspicious areas (winner maps to small party with positive excess): {len(suspicious)}\")\nsuspicious.head(20)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "exuirihp49",
   "source": "### Statistical test: Do same-numbered party-list parties get more votes?\n\nCompare two groups across all areas:\n- **Treatment**: the party-list party whose number matches the winning constituency candidate's number\n- **Control**: all other small party-list parties in the same area\n\nIf vote-buying spillover exists, the treatment group should have significantly higher vote shares than the control.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "606qamu902b",
   "source": "from scipy import stats\n\n# Identify small parties (national party-list share < 2%)\nsmall_party_codes = set(pl_national[pl_national[\"nationalPct\"] < 2][\"partyCode\"])\n\n# For each area, get the winner's candidateNo\nwinners_no = (\n    const_with_no[const_with_no[\"rank\"] == 1]\n    [[\"areaCode\", \"candidateNo\", \"partyCode\", \"voteTotal\"]]\n    .rename(columns={\"partyCode\": \"winnerPartyCode\", \"voteTotal\": \"winnerVotes\"})\n)\n\n# Get all party-list results for small parties, per area\npl_small = pl_df[pl_df[\"partyCode\"].isin(small_party_codes)][\n    [\"areaCode\", \"partyCode\", \"partyNo\", \"voteTotal_pl\", \"votePercent_pl\", \"goodVotes_pl\"]\n].copy()\n\n# Merge to know the winner's candidateNo in each area\npl_small = pl_small.merge(winners_no[[\"areaCode\", \"candidateNo\"]], on=\"areaCode\", how=\"left\")\n\n# Flag: does this small party's number match the winner's candidate number?\npl_small[\"isMatchedNumber\"] = pl_small[\"partyNo\"] == pl_small[\"candidateNo\"]\n\ntreatment = pl_small[pl_small[\"isMatchedNumber\"]][\"votePercent_pl\"].dropna()\ncontrol = pl_small[~pl_small[\"isMatchedNumber\"]][\"votePercent_pl\"].dropna()\n\nprint(f\"Treatment (matched number): n={len(treatment)}, mean={treatment.mean():.4f}%, median={treatment.median():.4f}%\")\nprint(f\"Control (unmatched):        n={len(control)}, mean={control.mean():.4f}%, median={control.median():.4f}%\")\nprint(f\"Ratio of means: {treatment.mean() / control.mean():.2f}x\")\nprint()\n\n# Mann-Whitney U test (non-parametric, doesn't assume normality)\nu_stat, p_val = stats.mannwhitneyu(treatment, control, alternative=\"greater\")\nprint(f\"Mann-Whitney U test (treatment > control): U={u_stat:,.0f}, p={p_val:.2e}\")\n\n# Also Welch's t-test\nt_stat, p_val_t = stats.ttest_ind(treatment, control, equal_var=False, alternative=\"greater\")\nprint(f\"Welch's t-test (treatment > control): t={t_stat:.2f}, p={p_val_t:.2e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bg75av69sjj",
   "source": "# ── Extend to top-3 candidates (not just winner) ─────────────────────\n# Voters may also remember the numbers of runner-up candidates being promoted\ntop3_no = (\n    const_with_no[const_with_no[\"rank\"] <= 3]\n    [[\"areaCode\", \"candidateNo\", \"rank\", \"voteTotal\", \"votePercent\"]]\n)\n\npl_small2 = pl_df[pl_df[\"partyCode\"].isin(small_party_codes)][\n    [\"areaCode\", \"partyCode\", \"partyNo\", \"voteTotal_pl\", \"votePercent_pl\", \"goodVotes_pl\"]\n].copy()\n\n# Cross-join: for each area, check if any of the top-3 candidate numbers match\npl_small2 = pl_small2.merge(top3_no, on=\"areaCode\", how=\"left\")\npl_small2[\"isMatchedNumber\"] = pl_small2[\"partyNo\"] == pl_small2[\"candidateNo\"]\n\n# For each (area, small-party), flag if ANY top-3 candidate matches its number\nmatched_any = (\n    pl_small2[pl_small2[\"isMatchedNumber\"]]\n    .groupby([\"areaCode\", \"partyCode\"])\n    .agg(\n        matched_rank=(\"rank\", \"min\"),  # best-ranked matching candidate\n        matched_constVotes=(\"voteTotal\", \"max\"),\n        matched_constPct=(\"votePercent\", \"max\"),\n    )\n    .reset_index()\n)\n\npl_area_party = (\n    pl_small2\n    .drop_duplicates([\"areaCode\", \"partyCode\"])\n    [[\"areaCode\", \"partyCode\", \"partyNo\", \"voteTotal_pl\", \"votePercent_pl\", \"goodVotes_pl\"]]\n)\npl_area_party = pl_area_party.merge(matched_any, on=[\"areaCode\", \"partyCode\"], how=\"left\")\npl_area_party[\"isMatched\"] = pl_area_party[\"matched_rank\"].notna()\n\ntreat2 = pl_area_party[pl_area_party[\"isMatched\"]][\"votePercent_pl\"].dropna()\nctrl2 = pl_area_party[~pl_area_party[\"isMatched\"]][\"votePercent_pl\"].dropna()\n\nprint(\"Extended test (matching ANY top-3 candidate number):\")\nprint(f\"  Treatment: n={len(treat2)}, mean={treat2.mean():.4f}%, median={treat2.median():.4f}%\")\nprint(f\"  Control:   n={len(ctrl2)}, mean={ctrl2.mean():.4f}%, median={ctrl2.median():.4f}%\")\nprint(f\"  Ratio of means: {treat2.mean() / ctrl2.mean():.2f}x\")\nu2, p2 = stats.mannwhitneyu(treat2, ctrl2, alternative=\"greater\")\nprint(f\"  Mann-Whitney p={p2:.2e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b72eetqkkmn",
   "source": "# ── Visualization 1: Distribution of party-list vote % (matched vs unmatched) ──\nfig, axes = plt.subplots(1, 2, figsize=(16, 5))\n\n# Histogram\nbins = np.linspace(0, max(treat2.quantile(0.99), ctrl2.quantile(0.99)), 50)\naxes[0].hist(ctrl2, bins=bins, alpha=0.6, label=f\"Unmatched (n={len(ctrl2):,})\", density=True, color=\"steelblue\")\naxes[0].hist(treat2, bins=bins, alpha=0.6, label=f\"Matched number (n={len(treat2):,})\", density=True, color=\"coral\")\naxes[0].set_xlabel(\"Party-list vote %\")\naxes[0].set_ylabel(\"Density\")\naxes[0].set_title(\"Small party vote % distribution: matched vs unmatched number\")\naxes[0].legend()\n\n# Box plot\ndata_box = pd.DataFrame({\n    \"vote_pct\": pd.concat([treat2, ctrl2]),\n    \"group\": [\"Matched\\n(same number)\"] * len(treat2) + [\"Unmatched\\n(different number)\"] * len(ctrl2)\n})\ndata_box.boxplot(column=\"vote_pct\", by=\"group\", ax=axes[1], showfliers=False)\naxes[1].set_title(\"Party-list vote % by matching status\")\naxes[1].set_ylabel(\"Party-list vote %\")\naxes[1].set_xlabel(\"\")\nfig.suptitle(\"\")\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "xgg9zng4ad",
   "source": "# ── Visualization 2: Scatter — constituency candidate votes vs same-numbered party-list votes ──\n# For matched pairs only, does a stronger constituency candidate produce more party-list spillover?\nmatched_pairs = pl_area_party[pl_area_party[\"isMatched\"]].copy()\nmatched_pairs = matched_pairs.merge(\n    pl_national[[\"partyCode\", \"nationalPct\"]],\n    on=\"partyCode\", how=\"left\"\n)\nmatched_pairs[\"excess_pct\"] = matched_pairs[\"votePercent_pl\"] - matched_pairs[\"nationalPct\"]\n\nfig, ax = plt.subplots(figsize=(10, 7))\nsc = ax.scatter(\n    matched_pairs[\"matched_constPct\"],\n    matched_pairs[\"excess_pct\"],\n    c=matched_pairs[\"matched_rank\"],\n    cmap=\"RdYlGn_r\",\n    alpha=0.5,\n    s=30,\n    edgecolors=\"gray\",\n    linewidths=0.3,\n)\nax.axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\nax.set_xlabel(\"Constituency candidate vote % (whose number matches)\")\nax.set_ylabel(\"Excess party-list vote % (above national avg)\")\nax.set_title(\"Does a stronger constituency candidate produce more party-list spillover\\nfor the same-numbered small party?\")\ncbar = plt.colorbar(sc, ax=ax)\ncbar.set_label(\"Constituency rank of matched candidate\")\n\n# Regression line\nmask = matched_pairs[[\"matched_constPct\", \"excess_pct\"]].dropna()\nslope, intercept, r, p, se = stats.linregress(mask[\"matched_constPct\"], mask[\"excess_pct\"])\nx_line = np.linspace(mask[\"matched_constPct\"].min(), mask[\"matched_constPct\"].max(), 100)\nax.plot(x_line, slope * x_line + intercept, \"r-\", linewidth=2,\n        label=f\"r={r:.3f}, p={p:.2e}\")\nax.legend()\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "zw1uqctusxj",
   "source": "# ── Visualization 3: Breakdown by region ─────────────────────────────\n# Vote-buying is more common in rural areas — does the effect vary by region?\nmatched_with_region = pl_area_party[pl_area_party[\"isMatched\"]].merge(\n    area_meta[[\"areaCode\", \"regionName\"]], on=\"areaCode\", how=\"left\"\n)\nmatched_with_region = matched_with_region.merge(\n    pl_national[[\"partyCode\", \"nationalPct\"]], on=\"partyCode\", how=\"left\"\n)\nmatched_with_region[\"excess_pct\"] = matched_with_region[\"votePercent_pl\"] - matched_with_region[\"nationalPct\"]\n\nunmatched_with_region = pl_area_party[~pl_area_party[\"isMatched\"]].merge(\n    area_meta[[\"areaCode\", \"regionName\"]], on=\"areaCode\", how=\"left\"\n)\nunmatched_with_region = unmatched_with_region.merge(\n    pl_national[[\"partyCode\", \"nationalPct\"]], on=\"partyCode\", how=\"left\"\n)\nunmatched_with_region[\"excess_pct\"] = unmatched_with_region[\"votePercent_pl\"] - unmatched_with_region[\"nationalPct\"]\n\nregion_order = [\"กรุงเทพมหานคร\", \"กลาง\", \"ตะวันออก\", \"เหนือ\", \"ตะวันออกเฉียงเหนือ\", \"ใต้\"]\nregion_labels = [\"Bangkok\", \"Central\", \"East\", \"North\", \"Northeast\", \"South\"]\n\nfig, ax = plt.subplots(figsize=(14, 6))\nx = np.arange(len(region_order))\nwidth = 0.35\n\nmatched_means = [matched_with_region[matched_with_region[\"regionName\"] == r][\"excess_pct\"].mean() for r in region_order]\nunmatched_means = [unmatched_with_region[unmatched_with_region[\"regionName\"] == r][\"excess_pct\"].mean() for r in region_order]\n\nbars1 = ax.bar(x - width/2, matched_means, width, label=\"Matched number\", color=\"coral\", alpha=0.8)\nbars2 = ax.bar(x + width/2, unmatched_means, width, label=\"Unmatched number\", color=\"steelblue\", alpha=0.8)\n\nax.set_xlabel(\"Region\")\nax.set_ylabel(\"Mean excess party-list vote % (vs national avg)\")\nax.set_title(\"Number spillover effect by region\\n(higher = more excess votes for same-numbered party)\")\nax.set_xticks(x)\nax.set_xticklabels(region_labels)\nax.axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\nax.legend()\n\n# Add count labels\nfor i, r in enumerate(region_order):\n    n = len(matched_with_region[matched_with_region[\"regionName\"] == r])\n    ax.text(x[i] - width/2, matched_means[i] + 0.01, f\"n={n}\", ha=\"center\", va=\"bottom\", fontsize=8)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "u5hkkvj9th",
   "source": "# ── Visualization 4: Per-party-number breakdown ──────────────────────\n# Which small party numbers benefit most from spillover?\n# This shows: for party-list party #N, how much more do they get in areas where\n# a top-3 constituency candidate also has number N?\n\nparty_effect = (\n    pl_area_party\n    .merge(pl_national[[\"partyCode\", \"nationalPct\"]], on=\"partyCode\", how=\"left\")\n    .assign(excess_pct=lambda d: d[\"votePercent_pl\"] - d[\"nationalPct\"])\n)\n\neffect_by_party = (\n    party_effect\n    .groupby([\"partyNo\", \"isMatched\"])\n    .agg(mean_excess=(\"excess_pct\", \"mean\"), n=(\"excess_pct\", \"count\"))\n    .reset_index()\n    .pivot(index=\"partyNo\", columns=\"isMatched\", values=[\"mean_excess\", \"n\"])\n)\neffect_by_party.columns = [\"excess_unmatched\", \"excess_matched\", \"n_unmatched\", \"n_matched\"]\neffect_by_party[\"spillover_delta\"] = effect_by_party[\"excess_matched\"] - effect_by_party[\"excess_unmatched\"]\neffect_by_party = effect_by_party.dropna().sort_values(\"spillover_delta\", ascending=False)\n\n# Add party names\neffect_by_party = effect_by_party.reset_index().merge(\n    party_df[[\"partyNo\", \"partyName\"]], on=\"partyNo\", how=\"left\"\n)\n\nfig, ax = plt.subplots(figsize=(14, 6))\ncolors = [\"coral\" if x > 0 else \"steelblue\" for x in effect_by_party[\"spillover_delta\"]]\nbars = ax.barh(\n    [f\"#{row.partyNo} {row.partyName}\" for _, row in effect_by_party.iterrows()],\n    effect_by_party[\"spillover_delta\"],\n    color=colors,\n    alpha=0.8,\n)\nax.set_xlabel(\"Spillover delta (matched excess - unmatched excess, percentage points)\")\nax.set_title(\"Which small party-list parties benefit most from number matching?\\n(positive = gets more votes when a top-3 constituency candidate shares their number)\")\nax.axvline(0, color=\"black\", linewidth=0.8)\n\nplt.tight_layout()\nplt.show()\n\neffect_by_party[[\"partyNo\", \"partyName\", \"n_matched\", \"excess_matched\", \"excess_unmatched\", \"spillover_delta\"]].round(3)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "w63t8vllakf",
   "source": "### Dose-response: Does the effect scale with constituency vote strength?\n\nIf the hypothesis is real, the spillover should be **stronger** when the matched constituency candidate won by a larger margin (more voters told to \"remember the number\").",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "egshsc29ww",
   "source": "# ── Dose-response: bin by constituency candidate strength ────────────\nmatched_dose = matched_pairs.copy()\nmatched_dose[\"const_bin\"] = pd.qcut(matched_dose[\"matched_constPct\"], q=5, labels=[\n    \"Q1 (weakest)\", \"Q2\", \"Q3\", \"Q4\", \"Q5 (strongest)\"\n])\n\ndose_stats = (\n    matched_dose\n    .groupby(\"const_bin\", observed=True)\n    .agg(\n        mean_excess=(\"excess_pct\", \"mean\"),\n        median_excess=(\"excess_pct\", \"median\"),\n        n=(\"excess_pct\", \"count\"),\n        mean_const_pct=(\"matched_constPct\", \"mean\"),\n    )\n)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(dose_stats.index, dose_stats[\"mean_excess\"], color=\"coral\", alpha=0.8, edgecolor=\"gray\")\nax.set_xlabel(\"Constituency candidate strength (quintiles)\")\nax.set_ylabel(\"Mean excess party-list vote %\")\nax.set_title(\"Dose-response: Does stronger constituency candidate → more party-list spillover?\")\nax.axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\n\nfor i, (idx, row) in enumerate(dose_stats.iterrows()):\n    ax.text(i, row[\"mean_excess\"] + 0.005, f\"n={int(row['n'])}\\navg={row['mean_const_pct']:.0f}%\",\n            ha=\"center\", va=\"bottom\", fontsize=8)\n\nplt.tight_layout()\nplt.show()\n\ndose_stats",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "v8u7bewju6",
   "source": "# ── Visualization 5: Top 30 most suspicious areas ────────────────────\n# Areas where a winning candidate's number maps to a small party that got huge excess\ntop_suspicious = suspicious.head(30).copy()\ntop_suspicious[\"label\"] = (\n    top_suspicious[\"provinceName\"] + \" เขต \" + top_suspicious[\"areaCode\"].str.extract(r\"(\\d+)$\")[0].astype(str)\n)\n\nfig, ax = plt.subplots(figsize=(14, 8))\ncolors_bar = top_suspicious[\"pl_excess_pct\"].apply(lambda x: \"darkred\" if x > 1 else \"coral\")\nax.barh(\n    top_suspicious[\"label\"][::-1],\n    top_suspicious[\"pl_excess_pct\"][::-1],\n    color=colors_bar[::-1],\n    alpha=0.8,\n    edgecolor=\"gray\",\n)\nax.set_xlabel(\"Excess party-list vote % (above national average)\")\nax.set_title(\"Top 30 most suspicious areas\\n(winning candidate's number = small party-list party's number)\")\n\n# Add annotations\nfor i, (_, row) in enumerate(top_suspicious[::-1].iterrows()):\n    ax.text(\n        row[\"pl_excess_pct\"] + 0.02,\n        i,\n        f\"cand #{int(row['candidateNo'])} ({row['partyName']}) → PL #{int(row['candidateNo'])} ({row['pl_partyName_sameNo']})\",\n        va=\"center\",\n        fontsize=7,\n    )\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9n5pqa65eig",
   "source": "### Suspicious activity by winning party\n\nWhich constituency-winning parties have the most areas where their candidate's ballot number caused anomalous spillover to a same-numbered small party-list party?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ohf34ncaq7i",
   "source": "# ── Suspicious activity summary by winning party ─────────────────────\n# `suspicious` df has all areas where rank-1 candidate's number matches a small\n# party-list party AND that party got positive excess votes.\n\n# Total seats won per party (for context / normalisation)\ntotal_seats = (\n    const_with_no[const_with_no[\"rank\"] == 1]\n    .groupby(\"partyName\")\n    .size()\n    .rename(\"total_seats_won\")\n)\n\n# Aggregate suspicious areas by winning party\nparty_suspicious = (\n    suspicious\n    .groupby(\"partyName\")\n    .agg(\n        suspicious_areas=(\"areaCode\", \"count\"),\n        mean_excess_pct=(\"pl_excess_pct\", \"mean\"),\n        median_excess_pct=(\"pl_excess_pct\", \"median\"),\n        max_excess_pct=(\"pl_excess_pct\", \"max\"),\n        total_excess_votes=(\"pl_excess_votes\", \"sum\"),\n        mean_winner_pct=(\"votePercent\", \"mean\"),\n    )\n    .join(total_seats)\n    .reset_index()\n)\nparty_suspicious[\"pct_of_seats_suspicious\"] = (\n    party_suspicious[\"suspicious_areas\"] / party_suspicious[\"total_seats_won\"] * 100\n)\nparty_suspicious = party_suspicious.sort_values(\"suspicious_areas\", ascending=False)\n\n# Also get party colors for the chart\nparty_suspicious = party_suspicious.merge(\n    party_df[[\"partyName\", \"partyColor\"]].drop_duplicates(), on=\"partyName\", how=\"left\"\n)\n\nparty_suspicious[\n    [\"partyName\", \"suspicious_areas\", \"total_seats_won\", \"pct_of_seats_suspicious\",\n     \"mean_excess_pct\", \"median_excess_pct\", \"max_excess_pct\",\n     \"total_excess_votes\", \"mean_winner_pct\"]\n].round(3)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gzp4bz9w646",
   "source": "# ── Chart: suspicious areas by party (absolute count + % of seats) ────\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\nps = party_suspicious.sort_values(\"suspicious_areas\", ascending=True)\ncolors_abs = [c if pd.notna(c) else \"#999999\" for c in ps[\"partyColor\"]]\n\n# Left: absolute count\naxes[0].barh(ps[\"partyName\"], ps[\"suspicious_areas\"], color=colors_abs, alpha=0.85, edgecolor=\"gray\")\naxes[0].set_xlabel(\"Number of suspicious areas\")\naxes[0].set_title(\"Suspicious areas by winning party\\n(absolute count)\")\nfor i, (_, row) in enumerate(ps.iterrows()):\n    axes[0].text(row[\"suspicious_areas\"] + 0.3, i,\n                 f'{int(row[\"suspicious_areas\"])} / {int(row[\"total_seats_won\"])} seats',\n                 va=\"center\", fontsize=8)\n\n# Right: % of seats that are suspicious\nps2 = party_suspicious[party_suspicious[\"total_seats_won\"] >= 3].sort_values(\"pct_of_seats_suspicious\", ascending=True)\ncolors_pct = [c if pd.notna(c) else \"#999999\" for c in ps2[\"partyColor\"]]\n\naxes[1].barh(ps2[\"partyName\"], ps2[\"pct_of_seats_suspicious\"], color=colors_pct, alpha=0.85, edgecolor=\"gray\")\naxes[1].set_xlabel(\"% of party's won seats that are suspicious\")\naxes[1].set_title(\"Suspicious rate by party\\n(parties with >= 3 seats)\")\nfor i, (_, row) in enumerate(ps2.iterrows()):\n    axes[1].text(row[\"pct_of_seats_suspicious\"] + 0.5, i,\n                 f'{row[\"pct_of_seats_suspicious\"]:.1f}%',\n                 va=\"center\", fontsize=8)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "y0ms5caqm2k",
   "source": "# ── Heatmap: excess votes by party × region ──────────────────────────\n# Which parties show the spillover effect in which regions?\n# `suspicious` already has regionName from the earlier merge with area_meta.\n\nregion_labels_map = dict(zip(\n    [\"กรุงเทพมหานคร\", \"กลาง\", \"ตะวันออก\", \"เหนือ\", \"ตะวันออกเฉียงเหนือ\", \"ใต้\"],\n    [\"Bangkok\", \"Central\", \"East\", \"North\", \"Northeast\", \"South\"],\n))\n\npivot_count = (\n    suspicious\n    .groupby([\"partyName\", \"regionName\"])\n    .size()\n    .unstack(fill_value=0)\n)\n# Reorder columns and rename to English\npivot_count = pivot_count.reindex(columns=region_labels_map.keys(), fill_value=0)\npivot_count.columns = [region_labels_map[c] for c in pivot_count.columns]\n\n# Only show parties with >= 2 suspicious areas\npivot_count = pivot_count[pivot_count.sum(axis=1) >= 2].sort_values(\n    pivot_count.columns.tolist(), ascending=False\n)\n\nfig, ax = plt.subplots(figsize=(10, max(4, len(pivot_count) * 0.5 + 1)))\nim = ax.imshow(pivot_count.values, cmap=\"OrRd\", aspect=\"auto\")\n\nax.set_xticks(range(len(pivot_count.columns)))\nax.set_xticklabels(pivot_count.columns)\nax.set_yticks(range(len(pivot_count.index)))\nax.set_yticklabels(pivot_count.index)\nax.set_title(\"Suspicious areas: party × region heatmap\")\n\n# Annotate cells with counts\nfor i in range(len(pivot_count.index)):\n    for j in range(len(pivot_count.columns)):\n        val = pivot_count.iloc[i, j]\n        if val > 0:\n            ax.text(j, i, str(val), ha=\"center\", va=\"center\",\n                    color=\"white\" if val > pivot_count.values.max() * 0.6 else \"black\",\n                    fontsize=11, fontweight=\"bold\")\n\nplt.colorbar(im, ax=ax, label=\"Count of suspicious areas\")\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7zod19k4a",
   "source": "### Spillover by every major-party candidate\n\nFor **every** constituency candidate from a major party (national party-list share ≥ 2%), not just winners, map their ballot number to the same-numbered small party-list party and show the excess votes. Each dot is one candidate, colored by their party.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6ca4oukm1q4",
   "source": "# ── Every major-party candidate's spillover effect ───────────────────\nMAJOR_PARTY_NAMES = [\"ภูมิใจไทย\", \"ประชาชน\", \"เพื่อไทย\", \"ประชาธิปัตย์\", \"กล้าธรรม\"]\nmajor_party_codes = set(party_df[party_df[\"partyName\"].isin(MAJOR_PARTY_NAMES)][\"partyCode\"])\n\n# ALL candidates from these parties (any rank)\nall_major = const_with_no[const_with_no[\"partyCode\"].isin(major_party_codes)].copy()\n\n# Map candidateNo → same-numbered party-list party\nall_major[\"pl_partyCode_sameNo\"] = all_major[\"candidateNo\"].map(partyno_to_code)\nall_major[\"pl_partyName_sameNo\"] = all_major[\"candidateNo\"].map(partyno_to_name)\n\n# Get the actual party-list vote for that same-numbered party in this area\nall_major = all_major.merge(pl_lookup, on=[\"areaCode\", \"pl_partyCode_sameNo\"], how=\"left\")\n\n# Add national average for the same-numbered party\nall_major = all_major.merge(pl_nat_lookup, on=\"pl_partyCode_sameNo\", how=\"left\")\n\n# Compute excess\nall_major[\"pl_excess_pct\"] = all_major[\"pl_sameNo_pct\"] - all_major[\"pl_sameNo_nationalPct\"]\n\n# Only keep cases where matched party is small (national < 2%) and has data\nall_major[\"pl_sameNo_isSmall\"] = all_major[\"pl_sameNo_nationalPct\"] < 2\nplot_df = all_major[all_major[\"pl_sameNo_isSmall\"] & all_major[\"pl_sameNo_pct\"].notna()].copy()\n\n# Use the specified party order\nparty_order = [p for p in MAJOR_PARTY_NAMES if p in plot_df[\"partyName\"].values]\nparty_color_map = party_df.drop_duplicates(\"partyName\").set_index(\"partyName\")[\"partyColor\"].to_dict()\n\nprint(f\"Major-party candidates with small-party spillover data: {len(plot_df):,}\")\nprint(f\"Parties: {party_order}\")\n\n# ── Plot 1: Strip plot — spillover excess by party ───────────────────\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\nrng_plot = np.random.default_rng(42)\nfor i, pname in enumerate(party_order):\n    subset = plot_df[plot_df[\"partyName\"] == pname]\n    color = party_color_map.get(pname, \"#999999\")\n    jitter = rng_plot.uniform(-0.3, 0.3, len(subset))\n    axes[0].scatter(\n        np.full(len(subset), i) + jitter,\n        subset[\"pl_excess_pct\"],\n        c=color, alpha=0.35, s=12, edgecolors=\"none\",\n    )\n    # Mean marker\n    axes[0].scatter(i, subset[\"pl_excess_pct\"].mean(), c=color,\n                    s=100, marker=\"D\", edgecolors=\"black\", linewidths=0.8, zorder=5)\n\naxes[0].set_xticks(range(len(party_order)))\naxes[0].set_xticklabels(party_order, rotation=45, ha=\"right\", fontsize=9)\naxes[0].axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\naxes[0].set_ylabel(\"Excess party-list vote % (same-numbered small party)\")\naxes[0].set_title(\"Spillover by major-party candidate\\n(each dot = one candidate, any rank; diamond = party mean)\")\naxes[0].set_xlim(-0.5, len(party_order) - 0.5)\n\n# ── Plot 2: Scatter — constituency vote % vs spillover, colored by party ──\nfor pname in party_order:\n    subset = plot_df[plot_df[\"partyName\"] == pname]\n    color = party_color_map.get(pname, \"#999999\")\n    axes[1].scatter(\n        subset[\"votePercent\"],\n        subset[\"pl_excess_pct\"],\n        c=color, alpha=0.4, s=15, edgecolors=\"none\",\n        label=pname,\n    )\n\naxes[1].axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\naxes[1].set_xlabel(\"Constituency candidate vote %\")\naxes[1].set_ylabel(\"Excess party-list vote % (same-numbered small party)\")\naxes[1].set_title(\"Dose-response by party\\n(stronger candidate → more spillover?)\")\naxes[1].legend(fontsize=8, loc=\"upper right\", framealpha=0.8)\n\n# Overall regression line\nvalid = plot_df[[\"votePercent\", \"pl_excess_pct\"]].dropna()\nslope, intercept, r, p, se = stats.linregress(valid[\"votePercent\"], valid[\"pl_excess_pct\"])\nx_line = np.linspace(valid[\"votePercent\"].min(), valid[\"votePercent\"].max(), 100)\naxes[1].plot(x_line, slope * x_line + intercept, \"k-\", linewidth=2,\n             label=f\"all: r={r:.3f}, p={p:.2e}\")\naxes[1].legend(fontsize=8, loc=\"upper right\", framealpha=0.8)\n\nplt.tight_layout()\nplt.show()\n\n# ── Summary table by party ───────────────────────────────────────────\nparty_stats = (\n    plot_df.groupby(\"partyName\")\n    .agg(\n        n_candidates=(\"areaCode\", \"count\"),\n        mean_excess=(\"pl_excess_pct\", \"mean\"),\n        median_excess=(\"pl_excess_pct\", \"median\"),\n        pct_positive=(\"pl_excess_pct\", lambda x: (x > 0).mean() * 100),\n        mean_const_pct=(\"votePercent\", \"mean\"),\n    )\n    .reindex(party_order)\n    .round(3)\n)\nparty_stats",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "g13xdcistto",
   "source": "### Placebo test: Randomized candidate numbers\n\nIf the effect is real, it should **disappear** when we randomly shuffle candidate numbers within each area. We run 1000 permutations and compare the real effect size against the null distribution.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "le9ez98ubmg",
   "source": "# ── Permutation test ─────────────────────────────────────────────────\nrng = np.random.default_rng(42)\n\n# Real effect: mean party-list vote % for matched vs unmatched\nreal_diff = treat2.mean() - ctrl2.mean()\n\n# Base data: all small-party party-list observations with area's winner candidateNo\nbase = pl_small.drop_duplicates([\"areaCode\", \"partyCode\"]).copy()\nbase = base[base[\"votePercent_pl\"].notna()].copy()\n\n# For permutation: shuffle candidateNo within each area, then recompute matched/unmatched\nn_perms = 1000\nperm_diffs = []\n\n# Pre-group for speed\narea_groups = base.groupby(\"areaCode\")\n\nfor _ in range(n_perms):\n    # Shuffle the winner's candidateNo assignment across areas\n    shuffled = base.copy()\n    # Randomly reassign candidateNo (winner's number) across areas\n    area_codes = shuffled[\"areaCode\"].unique()\n    cand_nos = shuffled.groupby(\"areaCode\")[\"candidateNo\"].first().values.copy()\n    rng.shuffle(cand_nos)\n    shuffle_map = dict(zip(area_codes, cand_nos))\n    shuffled[\"candidateNo\"] = shuffled[\"areaCode\"].map(shuffle_map)\n    shuffled[\"isMatchedNumber\"] = shuffled[\"partyNo\"] == shuffled[\"candidateNo\"]\n\n    treat_perm = shuffled[shuffled[\"isMatchedNumber\"]][\"votePercent_pl\"]\n    ctrl_perm = shuffled[~shuffled[\"isMatchedNumber\"]][\"votePercent_pl\"]\n    if len(treat_perm) > 0 and len(ctrl_perm) > 0:\n        perm_diffs.append(treat_perm.mean() - ctrl_perm.mean())\n\nperm_diffs = np.array(perm_diffs)\np_perm = (perm_diffs >= real_diff).mean()\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.hist(perm_diffs, bins=50, alpha=0.7, color=\"steelblue\", edgecolor=\"gray\", density=True)\nax.axvline(real_diff, color=\"red\", linewidth=2, linestyle=\"--\", label=f\"Observed diff = {real_diff:.4f}\")\nax.set_xlabel(\"Mean difference (matched - unmatched) in party-list vote %\")\nax.set_ylabel(\"Density\")\nax.set_title(f\"Permutation test (n={n_perms}): p = {p_perm:.4f}\")\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Observed difference: {real_diff:.4f} percentage points\")\nprint(f\"Permutation p-value: {p_perm:.4f}\")\nprint(f\"95th percentile of null: {np.percentile(perm_diffs, 95):.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "kuas6r67yqi",
   "source": "### Summary of findings\n\n| Analysis | What it tests | Key metric |\n|----------|-------------|-----------|\n| **Treatment vs Control** | Do same-numbered small parties get more votes? | Mean vote % difference |\n| **Scatter + regression** | Does stronger constituency candidate → bigger spillover? | Correlation r and p-value |\n| **Regional breakdown** | Is the effect stronger in rural regions? | Excess vote % by region |\n| **Per-party breakdown** | Which small party numbers benefit most? | Spillover delta |\n| **Dose-response** | Does the effect scale with candidate strength? | Monotonic trend in quintiles |\n| **Permutation test** | Could the effect be due to chance? | p-value vs shuffled null |\n| **Top suspicious areas** | Where is the effect most extreme? | Ranked list of areas |",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}